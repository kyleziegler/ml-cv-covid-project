{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac519b0-ff51-49eb-8cb8-78213a72b7fe",
   "metadata": {},
   "source": [
    "# Computer Vision, Image Classification - Covid CT Scans\n",
    "Kyle Ziegler 4/2022\n",
    "\n",
    "Dataset info: [Kaggle](https://www.kaggle.com/datasets/hgunraj/covidxct), 60GB, 200k images with bounding boxes and classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b170cdda-1f16-4480-8404-829c59a8673f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d8327f-451c-47bd-9c60-c6a0421f4049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "image_channels = 3\n",
    "height, width = 300,300\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    def create_model():\n",
    "        #create the common input layer\n",
    "\n",
    "        input_shape = (height, width, image_channels)\n",
    "        input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "        #create the base layers\n",
    "        # base_layers = layers.experimental.preprocessing.Rescaling(1./255, name='bl_1')(input_layer)\n",
    "        # base_layers = layers.Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(base_layers)\n",
    "        base_layers = layers.Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(input_layer)\n",
    "        base_layers = layers.MaxPooling2D(name='bl_3')(base_layers)\n",
    "        base_layers = layers.Conv2D(32, 3, padding='same', activation='relu', name='bl_4')(base_layers)\n",
    "        base_layers = layers.MaxPooling2D(name='bl_5')(base_layers)\n",
    "        base_layers = layers.Conv2D(64, 3, padding='same', activation='relu', name='bl_6')(base_layers)\n",
    "        base_layers = layers.MaxPooling2D(name='bl_7')(base_layers)\n",
    "        base_layers = layers.Flatten(name='bl_8')(base_layers)\n",
    "        # shivaji - add your heads to a pre-built model\n",
    "\n",
    "        #create the classifier branch\n",
    "        classifier_branch = layers.Dense(128, activation='relu', name='cl_1')(base_layers)\n",
    "        classifier_branch = layers.Dense(num_classes, name='cl_head')(classifier_branch)\n",
    "        # logisitic regression for each posible class\n",
    "\n",
    "        #create the localiser branch\n",
    "        locator_branch = layers.Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "        locator_branch = layers.Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
    "        locator_branch = layers.Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
    "        locator_branch = layers.Dense(4, activation='sigmoid', name='bb_head')(locator_branch)\n",
    "        # output 4 floats, MSE loss metric\n",
    "\n",
    "        model = tf.keras.Model(input_layer, outputs=[classifier_branch,locator_branch])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def create_transfer_learning_model():\n",
    "        \n",
    "        base_model = tf.keras.applications.ResNet101V2(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=(height, width, image_channels),\n",
    "            pooling=\"avg\",\n",
    "            classifier_activation=None, # only used when you are including the top\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        input_shape = (height, width, image_channels)\n",
    "        input_layer = tf.keras.layers.Input(input_shape)\n",
    "        \n",
    "        base_layers = base_model(input_layer, training=False)\n",
    "        \n",
    "        # base_model.add(Flatten())\n",
    "        # flatten = tf.keras.layers.Flatten()(base_model.layers[-1].output)\n",
    "        \n",
    "        #create the classifier branch\n",
    "        classifier_branch = layers.Dense(128, activation='relu', name='cl_1')(base_layers)\n",
    "        classifier_branch = layers.Dense(num_classes, name='cl_head')(classifier_branch)\n",
    "        # logisitic regression for each posible class\n",
    "\n",
    "        #create the localiser branch\n",
    "        locator_branch = layers.Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "        locator_branch = layers.Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
    "        locator_branch = layers.Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
    "        locator_branch = layers.Dense(4, activation='sigmoid', name='bb_head')(locator_branch)\n",
    "        # output 4 floats, MSE loss metric\n",
    "\n",
    "        model = tf.keras.Model(input_layer, outputs=[classifier_branch,locator_branch])\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = create_transfer_learning_model()\n",
    "    \n",
    "    \n",
    "tf.keras.utils.plot_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136e1105-0dee-4edb-8db0-e48b6e299e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 300, 300, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resnet101v2 (Functional)       (None, 2048)         42626560    ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " bb_1 (Dense)                   (None, 128)          262272      ['resnet101v2[0][0]']            \n",
      "                                                                                                  \n",
      " bb_2 (Dense)                   (None, 64)           8256        ['bb_1[0][0]']                   \n",
      "                                                                                                  \n",
      " cl_1 (Dense)                   (None, 128)          262272      ['resnet101v2[0][0]']            \n",
      "                                                                                                  \n",
      " bb_3 (Dense)                   (None, 32)           2080        ['bb_2[0][0]']                   \n",
      "                                                                                                  \n",
      " cl_head (Dense)                (None, 4)            516         ['cl_1[0][0]']                   \n",
      "                                                                                                  \n",
      " bb_head (Dense)                (None, 4)            132         ['bb_3[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,162,088\n",
      "Trainable params: 535,528\n",
      "Non-trainable params: 42,626,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa416d13-1053-4216-b272-3c9c04e54905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can either define sparse categorical crossentropy here, or one hot encode the feature before getting here.\n",
    "losses = {\"cl_head\":tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "          \"bb_head\":tf.keras.losses.MSE\n",
    "        }\n",
    "\n",
    "metrics = {\"cl_head\":\"accuracy\",\n",
    "           \"bb_head\": \"mean_squared_error\"\n",
    "        }\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss=losses, optimizer=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3733f3-c242-47fe-8707-ee93a5832bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Prefetch Dataset From gs://vertex-central-1f/covid_proj_tfrecords/train/TFRECORD*\n",
      "Tensor(\"Identity:0\", shape=(300, 300, 3), dtype=float32)\n",
      "<RepeatDataset element_spec=(TensorSpec(shape=(256, 300, 300, 3), dtype=tf.float32, name=None), (TensorSpec(shape=(256,), dtype=tf.int64, name=None), TensorSpec(shape=(256, 4), dtype=tf.float32, name=None)))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "channels = 3\n",
    "\n",
    "def parse_record(record):\n",
    "    # print(tfrec)\n",
    "\n",
    "    feature_mapping = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        'bounding_box': tf.io.FixedLenFeature([4], tf.float32),  # shape [] means single element\n",
    "        'target_class': tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    \n",
    "    file_rec = tf.io.parse_single_example(record, feature_mapping)\n",
    "    \n",
    "    image = file_rec[\"image\"]\n",
    "    image = tf.io.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, (height, width))\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # normalizes between [0,1]\n",
    "    print(image)\n",
    "    \n",
    "    # print(image)\n",
    "    \n",
    "    bounding_box = file_rec[\"bounding_box\"]\n",
    "    \n",
    "    target_class = file_rec[\"target_class\"]\n",
    "    \n",
    "    return image, (target_class, bounding_box)\n",
    "\n",
    "def create_prefetch_dataset(file_path):\n",
    "    print('Creating Prefetch Dataset From', file_path)\n",
    "\n",
    "    # list_files have shuffle True by default\n",
    "    dataset = tf.data.Dataset.list_files(file_path)\n",
    "    \n",
    "    # A note on caching with cache(), you should only use this on small datasets \n",
    "    # that fit into memory, otherwise you'll crash your machine.\n",
    "    \n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\\\n",
    "    .repeat(-1)\n",
    "    \n",
    "    # Repeat creates an infinite loop, but the optimizer will stop when we are not making \n",
    "    # any progress. You also set a number of epochs.\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = create_prefetch_dataset(\"gs://vertex-central-1f/covid_proj_tfrecords/train/TFRECORD*\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fe13d5b-4f44-4f47-b09a-9aa2489f6dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './logs/fit/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./logs/fit/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33d93b-b8bc-4ef1-a95a-54e449db5533",
   "metadata": {},
   "source": [
    "### KZ notes on performance\n",
    "- When using a batch size of 256, main mem is around 15GB used, slightly increasing over each epoch.\n",
    "- CPU is around 10 cores at 100%, fluctuating between 5-11 cores.\n",
    "- GPU is around 75-95% utilization, only dropping for a second between epochs. GPU mem is at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b6d0a-00d3-479a-b8f2-10c0f01406fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "761/761 [==============================] - 142s 185ms/step - loss: 12.7085 - cl_head_loss: 12.1545 - bb_head_loss: 0.5539 - cl_head_accuracy: 0.2459 - bb_head_mean_squared_error: 0.5539\n",
      "Epoch 2/50\n",
      "761/761 [==============================] - 133s 175ms/step - loss: 12.5611 - cl_head_loss: 12.0084 - bb_head_loss: 0.5527 - cl_head_accuracy: 0.2550 - bb_head_mean_squared_error: 0.5527\n",
      "Epoch 3/50\n",
      "761/761 [==============================] - 136s 178ms/step - loss: 12.6104 - cl_head_loss: 12.0574 - bb_head_loss: 0.5530 - cl_head_accuracy: 0.2519 - bb_head_mean_squared_error: 0.5530\n",
      "Epoch 4/50\n",
      "761/761 [==============================] - 135s 177ms/step - loss: 12.7136 - cl_head_loss: 12.1603 - bb_head_loss: 0.5533 - cl_head_accuracy: 0.2455 - bb_head_mean_squared_error: 0.5533\n",
      "Epoch 5/50\n",
      "761/761 [==============================] - 133s 175ms/step - loss: 12.6273 - cl_head_loss: 12.0736 - bb_head_loss: 0.5537 - cl_head_accuracy: 0.2509 - bb_head_mean_squared_error: 0.5537\n",
      "Epoch 6/50\n",
      "761/761 [==============================] - 134s 176ms/step - loss: 12.5333 - cl_head_loss: 11.9801 - bb_head_loss: 0.5532 - cl_head_accuracy: 0.2567 - bb_head_mean_squared_error: 0.5532\n",
      "Epoch 7/50\n",
      "761/761 [==============================] - 135s 177ms/step - loss: 12.1265 - cl_head_loss: 11.5745 - bb_head_loss: 0.5521 - cl_head_accuracy: 0.2819 - bb_head_mean_squared_error: 0.5521\n",
      "Epoch 8/50\n",
      "761/761 [==============================] - 134s 177ms/step - loss: 12.9336 - cl_head_loss: 12.3791 - bb_head_loss: 0.5546 - cl_head_accuracy: 0.2320 - bb_head_mean_squared_error: 0.5546\n",
      "Epoch 9/50\n",
      "761/761 [==============================] - 137s 180ms/step - loss: 13.0573 - cl_head_loss: 12.5033 - bb_head_loss: 0.5540 - cl_head_accuracy: 0.2243 - bb_head_mean_squared_error: 0.5540\n",
      "Epoch 10/50\n",
      "761/761 [==============================] - 133s 175ms/step - loss: 11.9443 - cl_head_loss: 11.3924 - bb_head_loss: 0.5520 - cl_head_accuracy: 0.2932 - bb_head_mean_squared_error: 0.5520\n",
      "Epoch 11/50\n",
      "761/761 [==============================] - 134s 176ms/step - loss: 12.7627 - cl_head_loss: 12.2093 - bb_head_loss: 0.5534 - cl_head_accuracy: 0.2425 - bb_head_mean_squared_error: 0.5534\n",
      "Epoch 12/50\n",
      "761/761 [==============================] - 134s 176ms/step - loss: 12.4490 - cl_head_loss: 11.8961 - bb_head_loss: 0.5529 - cl_head_accuracy: 0.2619 - bb_head_mean_squared_error: 0.5529\n",
      "Epoch 28/50\n",
      "761/761 [==============================] - 134s 177ms/step - loss: 12.6078 - cl_head_loss: 12.0548 - bb_head_loss: 0.5531 - cl_head_accuracy: 0.2521 - bb_head_mean_squared_error: 0.5531\n",
      "Epoch 29/50\n",
      "324/761 [===========>..................] - ETA: 1:14 - loss: 12.4192 - cl_head_loss: 11.8651 - bb_head_loss: 0.5541 - cl_head_accuracy: 0.2639 - bb_head_mean_squared_error: 0.5541"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "# ceil(num_samples / batch_size) = 195000/256 = 400\n",
    "\n",
    "steps = 195000//BATCH_SIZE\n",
    "\n",
    "log_dir = os.getcwd() + '/fit/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# code for writing profile metrics, does not work in Vertex hosted Tensorboard 4/2022\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "#                                                       histogram_freq=1,\n",
    "#                                                       profile_batch = '0,10',\n",
    "#                                                       write_images=False\n",
    "#                                                      )\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                      histogram_freq=1,\n",
    "                                                     update_freq='epoch')\n",
    "    \n",
    "history = model.fit(dataset, epochs=50, steps_per_epoch=steps, initial_epoch = 0, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba0450e9-a4bd-4644-8e38-2fbdb173b77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+156596422468+locations+us-central1+tensorboards+3919064061672685568+experiments+model-fit\n",
      "WARNING:tensorboard:Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n",
      "\u001b[1m[2022-04-18T22:25:09]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-04-18T22:25:59]\u001b[0m Total uploaded: 90 scalars, 648 tensors (232.6 kB), 6 binary objects (513.0 kB)\n",
      "\u001b[2K\u001b[33mListening for new data in logdir...\u001b[0m\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 22:25:06.756706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 22:25:06.766530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 22:25:06.766860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "W0418 22:25:09.727760 139985401202496 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tb-gcp-uploader --tensorboard_resource_name \\\n",
    "  projects/156596422468/locations/us-central1/tensorboards/3919064061672685568 \\\n",
    "  --logdir=/home/jupyter/covid-proj/logs \\\n",
    "  --experiment_name=model-fit --one_shot=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97a2e8f6-d63f-493d-a146-bb8aaef65d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x7f21e02aafd0>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37ffd083-ad08-411d-af1d-198e7d0f2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 19:35:52.327380: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f23c88-380a-49a3-9955-c76a1419d789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
